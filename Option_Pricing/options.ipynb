{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/tmp/ipykernel_5629/4137522010.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"sentiment\"] = sentiment_scores  # Assign adjusted sentiment scores\n",
      "/tmp/ipykernel_5629/4137522010.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['trend_encoded'] = label_encoder.fit_transform(df['trend'])\n",
      "/tmp/ipykernel_5629/4137522010.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"sentiment\"] = sentiment_scores  # Assign adjusted sentiment scores\n",
      "/tmp/ipykernel_5629/4137522010.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['trend_encoded'] = label_encoder.fit_transform(df['trend'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.952931\n",
      "Epoch 2, Loss: 0.733387\n",
      "Epoch 3, Loss: 0.698653\n",
      "Epoch 4, Loss: 0.698015\n",
      "Epoch 5, Loss: 0.693927\n",
      "Epoch 6, Loss: 0.676571\n",
      "Epoch 7, Loss: 0.693214\n",
      "Epoch 8, Loss: 0.719585\n",
      "Epoch 9, Loss: 0.672143\n",
      "Epoch 10, Loss: 0.701457\n",
      "Epoch 11, Loss: 0.708492\n",
      "Epoch 12, Loss: 0.746761\n",
      "Epoch 13, Loss: 0.682691\n",
      "Epoch 14, Loss: 0.697453\n",
      "Epoch 15, Loss: 0.661455\n",
      "Epoch 16, Loss: 0.674350\n",
      "Epoch 17, Loss: 0.693382\n",
      "Epoch 18, Loss: 0.644918\n",
      "Epoch 19, Loss: 0.674579\n",
      "Epoch 20, Loss: 0.671891\n",
      "Training complete!\n",
      "Test Accuracy: 0.63\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from eventregistry import EventRegistry, QueryArticlesIter\n",
    "\n",
    "# Load Stock Data\n",
    "def load_stock_data(ticker, start_date, end_date):\n",
    "    df = yf.download(ticker, start=start_date, end=end_date)\n",
    "    df = df[['Close']]\n",
    "    df.columns = ['close']\n",
    "    df['trend'] = df['close'].diff().apply(lambda x: 'up' if x > 0 else ('down' if x < 0 else 'stable'))\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Load Sentiment Model\n",
    "def load_finbert():\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "    model = BertForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "    return tokenizer, model\n",
    "\n",
    "# Get Sentiment Scores\n",
    "def get_sentiment(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits.numpy()[0]\n",
    "    scores = softmax(outputs)\n",
    "    return scores[2] - scores[0]  # Positive - Negative Sentiment Score\n",
    "\n",
    "# Fetch Financial News from EventRegistry\n",
    "def fetch_news(api_key, company_uri):\n",
    "    er = EventRegistry(apiKey=api_key)\n",
    "    query = {\n",
    "        \"$query\": {\n",
    "            \"conceptUri\": company_uri\n",
    "        },\n",
    "        \"$filter\": {\n",
    "            \"forceMaxDataTimeWindow\": \"31\"\n",
    "        }\n",
    "    }\n",
    "    q = QueryArticlesIter.initWithComplexQuery(query)\n",
    "    articles = [article[\"title\"] for article in q.execQuery(er, maxItems=100)]\n",
    "    return articles\n",
    "\n",
    "# Prepare LSTM Data\n",
    "def prepare_data(df, sentiment_scores, sequence_length=10):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Ensure sentiment_scores has the same length as df\n",
    "    if len(sentiment_scores) == 0:\n",
    "        sentiment_scores = [0.0] * len(df)  # Default neutral sentiment\n",
    "    elif len(sentiment_scores) < len(df):\n",
    "        sentiment_scores = np.pad(sentiment_scores, (0, len(df) - len(sentiment_scores)), mode='edge')\n",
    "    else:\n",
    "        sentiment_scores = sentiment_scores[:len(df)]\n",
    "\n",
    "    df[\"sentiment\"] = sentiment_scores  # Assign adjusted sentiment scores\n",
    "    data = scaler.fit_transform(df[['close', 'sentiment']])\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    df['trend_encoded'] = label_encoder.fit_transform(df['trend'])\n",
    "    \n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequences.append(data[i:i+sequence_length])\n",
    "        targets.append(df['trend_encoded'].iloc[i+sequence_length])  # Predicting trend\n",
    "    \n",
    "    X = np.array(sequences)\n",
    "    Y = np.array(targets)\n",
    "    return X, Y, scaler, label_encoder\n",
    "\n",
    "\n",
    "# Define LSTM Model\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=50, num_layers=2, output_size=3):\n",
    "        super(StockLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return self.fc(lstm_out[:, -1, :])\n",
    "\n",
    "# Train LSTM Model\n",
    "def train_model(train_loader, input_size=2, epochs=20, lr=0.001):\n",
    "    model = StockLSTM(input_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for seqs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(seqs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    ticker = \"AAPL\"\n",
    "    start_date = \"2024-01-01\"\n",
    "    end_date = \"2025-01-01\"\n",
    "    api_key = \"17b19eac-bdd8-4730-beda-a2f58443ad43\"  # Replace with your EventRegistry API key\n",
    "    company_uri = \"http://en.wikipedia.org/wiki/Apple_Inc.\"\n",
    "    \n",
    "    df = load_stock_data(ticker, start_date, end_date)\n",
    "    tokenizer, model = load_finbert()\n",
    "    \n",
    "    news_headlines = fetch_news(api_key, company_uri)\n",
    "    sentiment_scores = [get_sentiment(text, tokenizer, model) for text in news_headlines]\n",
    "    \n",
    "    # Split stock data and sentiment into train/test\n",
    "    train_size = int(0.8 * len(df))\n",
    "    df_train, df_test = df.iloc[:train_size], df.iloc[train_size:]\n",
    "    sentiment_train, sentiment_test = sentiment_scores[:train_size], sentiment_scores[train_size:]\n",
    "    \n",
    "    seq_length = 10\n",
    "    X_train, Y_train, scaler, label_encoder = prepare_data(df_train, sentiment_train, seq_length)\n",
    "    X_test, Y_test, _, _ = prepare_data(df_test, sentiment_test, seq_length)\n",
    "    \n",
    "    train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), \n",
    "                               torch.tensor(Y_train, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    \n",
    "    model = train_model(train_loader)\n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    # Evaluate on Test Data\n",
    "    with torch.no_grad():\n",
    "        test_inputs = torch.tensor(X_test, dtype=torch.float32)\n",
    "        test_outputs = model(test_inputs)\n",
    "        predictions = torch.argmax(test_outputs, dim=1).numpy()\n",
    "        accuracy = np.mean(predictions == Y_test)\n",
    "        print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
